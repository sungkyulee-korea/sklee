name: Security AI Scan (Semgrep + OpenAI)

on:
  workflow_dispatch:
  pull_request:
    types: [opened, synchronize, reopened]
  push:
    branches: ['**']   # í•„ìš” ì‹œ ['main']ìœ¼ë¡œ ì œí•œ

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  ai-security-scan:
    runs-on: ubuntu-latest
    env:
      OPENAI_API_KEY: ${{ secrets.SKLEE_OPENAI_API_KEY }}
      MAX_FILE_BYTES: 150000
      MAX_DIFF_CHARS: 90000

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Get changed files & diff (PR or push)
        id: changed
        uses: actions/github-script@v7
        with:
          script: |
            const isPR = !!context.payload.pull_request;
            let diff = '';
            let files = [];

            if (isPR) {
              const prNumber = context.payload.pull_request.number;
              const list = await github.rest.pulls.listFiles({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: prNumber,
                per_page: 300
              });
              files = list.data.map(f => f.filename);

              const diffResp = await github.request(
                "GET /repos/{owner}/{repo}/pulls/{pull_number}",
                {
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  pull_number: prNumber,
                  mediaType: { format: "diff" }
                }
              );
              diff = diffResp.data || '';
            } else {
              const before = context.payload.before;
              const after  = context.payload.after;
              if (before && after && before !== '0000000000000000000000000000000000000000') {
                const comp = await github.rest.repos.compareCommits({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  base: before,
                  head: after
                });
                files = (comp.data.files || []).map(f => f.filename);
                diff = (comp.data.files || []).map(f =>
                  `--- ${f.filename}\n${f.patch || '[binary/no patch]'}\n`
                ).join("\n");
              } else {
                const tree = await github.rest.git.getTree({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  tree_sha: context.sha,
                  recursive: "1"
                }).catch(()=>({data:{tree:[]}}));
                files = (tree.data.tree || []).map(t => t.path).slice(0, 300);
                diff = '';
              }
            }

            const maxChars = parseInt(process.env.MAX_DIFF_CHARS || '90000', 10);
            if (diff.length > maxChars) diff = diff.slice(0, maxChars) + "\n\n[...diff truncated]";

            core.setOutput("files", files.join("\n"));
            core.setOutput("diff", diff);

      - name: Save changed files list
        run: |
          echo "${{ steps.changed.outputs.files }}" > changed_files_list.txt || true
          wc -l changed_files_list.txt || true

      - name: Read changed files contents (truncate large files)
        id: read_files
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const list = fs.existsSync('changed_files_list.txt') ? fs.readFileSync('changed_files_list.txt','utf8').split(/\r?\n/).filter(Boolean) : [];
            const maxBytes = parseInt(process.env.MAX_FILE_BYTES || '150000', 10);
            const out = {};
            for (const f of list) {
              try {
                if (fs.existsSync(f)) {
                  let s = fs.readFileSync(f,'utf8');
                  if (s.length > maxBytes) s = s.slice(0, maxBytes) + "\n\n[...truncated]";
                  out[f] = s;
                } else {
                  out[f] = '[file not checked out or binary]';
                }
              } catch (e) {
                out[f] = `[error reading file: ${String(e)}]`;
              }
            }
            fs.writeFileSync('changed_files_full.json', JSON.stringify(out, null, 2));
            core.setOutput('path','changed_files_full.json');

      - name: Setup Python for semgrep
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install semgrep (pip)
        run: |
          python -m pip install --upgrade pip
          pip install semgrep
          semgrep --version

      - name: Run semgrep (policy-based static scan)
        id: semgrep
        run: |
          semgrep --config p/ci --json --output semgrep-results.json || true
          if [ -f semgrep-results.json ]; then
            echo "Semgrep results saved to semgrep-results.json"
            if command -v jq >/dev/null 2>&1; then
              echo "Findings:" $(jq '.results | length' semgrep-results.json)
            fi
          else
            echo "No semgrep output file found."
          fi
        shell: bash

      - name: Choose files flagged by semgrep (or fallback to changed files)
        id: chosen
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let flagged = new Set();
            if (fs.existsSync('semgrep-results.json')) {
              try {
                const r = JSON.parse(fs.readFileSync('semgrep-results.json','utf8'));
                (r.results || []).forEach(item => {
                  if (item.path) flagged.add(item.path);
                });
              } catch(e) {}
            }
            if (flagged.size === 0) {
              const list = fs.existsSync('changed_files_list.txt') ? fs.readFileSync('changed_files_list.txt','utf8').split(/\r?\n/).filter(Boolean) : [];
              list.forEach(f => flagged.add(f));
            }
            const arr = Array.from(flagged).slice(0,100);
            fs.writeFileSync('files_to_analyze.json', JSON.stringify(arr, null, 2));
            core.setOutput('path','files_to_analyze.json');
            core.setOutput('count', arr.length.toString());

      - name: Heuristic pre-scan (regex signals)
        id: heuristics
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const files = fs.existsSync('files_to_analyze.json') ? JSON.parse(fs.readFileSync('files_to_analyze.json','utf8')) : [];
            const patterns = {
              XSS_output_like: /(response\.getWriter|getWriter\(|println\()/i,
              XSS_replaceAll: /\.replaceAll\(/i,
              SQL_concat_in_exec: /(execute(Query|Update)?\(|execute\().*\+.*/i,
              SQL_stmt: /\bnew\s+Statement\b|\bStatement\b/i,
              SQL_prepare_concat: /prepareStatement\(.+\+/i,
              LDAP_usage: /\b(InitialDirContext|DirContext|ldap|LDAP)\b/i,
              XPath_usage: /\bXPath\b|\bevaluate\(/i,
              File_read: /\bFileReader\b|\bBufferedReader\b|\breadLine\(/i
            };
            const out = {};
            for (const f of files) {
              const hits = [];
              try {
                if (fs.existsSync(f)) {
                  const lines = fs.readFileSync(f,'utf8').split(/\r?\n/);
                  lines.forEach((line, idx) => {
                    for (const [k, re] of Object.entries(patterns)) {
                      if (re.test(line)) {
                        hits.push({ line: idx+1, pattern: k, snippet: line.trim().slice(0,300) });
                      }
                    }
                  });
                } else {
                  // file not checked out / binary
                }
              } catch (e) {
                hits.push({ error: String(e) });
              }
              out[f] = hits;
            }
            fs.writeFileSync('heuristics.json', JSON.stringify(out, null, 2), 'utf8');
            core.setOutput('path','heuristics.json');

      - name: Call OpenAI for structured analysis (with heuristics & file list)
        id: call_openai
        uses: actions/github-script@v7
        env:
          OPENAI_API_KEY: ${{ env.OPENAI_API_KEY }}
        with:
          script: |
            const fs = require('fs');
            const apiKey = process.env.OPENAI_API_KEY || '';
            const files = fs.existsSync('files_to_analyze.json') ? JSON.parse(fs.readFileSync('files_to_analyze.json','utf8')) : [];
            const allFiles = fs.existsSync('changed_files_full.json') ? JSON.parse(fs.readFileSync('changed_files_full.json','utf8')) : {};
            const heur = fs.existsSync('heuristics.json') ? JSON.parse(fs.readFileSync('heuristics.json','utf8')) : {};
            let structured = { overall: "None", items: [] };

            if (!apiKey) {
              fs.writeFileSync('ai_summary_structured.json', JSON.stringify({overall:"Unknown", note:"OPENAI_API_KEY empty"}));
              return;
            }
            if (files.length === 0) {
              fs.writeFileSync('ai_summary_structured.json', JSON.stringify(structured));
              return;
            }

            // Build file list + heuristics text
            let fileListText = "Files to analyze (priority: filename containing 'bad' marked HIGH):\n";
            for (const f of files) {
              const priority = /bad/i.test(f) ? "HIGH" : "normal";
              fileListText += `- ${f} => ${priority}\n`;
            }

            let heurText = "Heuristic signals summary:\n";
            for (const f of Object.keys(heur)) {
              const arr = heur[f] || [];
              if (arr.length === 0) continue;
              heurText += `* ${f}:\n`;
              arr.slice(0,8).forEach(h => {
                heurText += `  - line ${h.line||'-'}: ${h.pattern||'-'} â†’ ${(h.snippet||h.error||'').replace(/\r?\n/g,' ').slice(0,200)}\n`;
              });
            }

            // Build limited contents block
            let filesBlock = "";
            for (const f of files) {
              const c = allFiles[f] || "[not available]";
              filesBlock += `--- ${f} ---\n`;
              filesBlock += (c.length > 120000 ? c.slice(0,120000) + "\n\n[...truncated]" : c) + "\n\n";
            }

            const prompt = [
              "You are a precise security code reviewer. For each file below, detect likely real vulnerabilities and map to CWE and OWASP Top10 if possible.",
              "Return valid JSON only with structure: { overall: 'Block'|'Manual review'|'Low'|'None', items:[{file,line,severity,cwe,owasp,present,details_ko,recommendation_ko}] }.",
              "Prioritize files marked HIGH (filename contains 'bad'). Only include items that are likely true vulnerabilities.",
              "",
              "FILES LIST:",
              fileListText,
              "",
              "HEURISTIC SIGNALS:",
              heurText,
              "",
              "FILE CONTENTS (truncated where needed):",
              filesBlock,
              "",
              "For each vulnerability include CWE code, OWASP mapping if possible, 1-line mitigation suggestion, brief Korean explanation (1-2 sentences).",
              "If no vulnerability for a file, include an item for that file with present:false and details_ko:'ì·¨ì•½ì  ì—†ìŒ'.",
            ].join("\n");

            const body = {
              model: "gpt-4o-mini",
              messages: [
                { role: "system", content: "You are a concise security-focused code reviewer. Produce JSON only." },
                { role: "user", content: prompt }
              ],
              temperature: 0,
              max_tokens: 1600
            };

            try {
              const resp = await fetch("https://api.openai.com/v1/chat/completions", {
                method: "POST",
                headers: {
                  "Authorization": `Bearer ${apiKey}`,
                  "Content-Type": "application/json"
                },
                body: JSON.stringify(body)
              });

              if (resp.ok) {
                const j = await resp.json();
                const text = j.choices?.[0]?.message?.content || '';
                try {
                  structured = JSON.parse(text);
                } catch (e) {
                  const m = text.match(/\{[\s\S]*\}$/);
                  if (m) {
                    try { structured = JSON.parse(m[0]); } catch(e2) { structured = { overall: "Unknown", note: "parse error", raw: text.slice(0,800) }; }
                  } else {
                    structured = { overall: "Unknown", note: "Non-JSON returned", raw: text.slice(0,800) };
                  }
                }
              } else {
                const t = await resp.text();
                structured = { overall: "Unknown", note: `[OpenAI error ${resp.status}] ${t.slice(0,800)}` };
              }
            } catch (e) {
              structured = { overall: "Unknown", note: "Fetch failed: " + String(e) };
            }

            fs.writeFileSync('ai_summary_structured.json', JSON.stringify(structured, null, 2));

      - name: Post structured Korean report (PR comment or Issue) including file list & heuristics
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const heur = fs.existsSync('heuristics.json') ? JSON.parse(fs.readFileSync('heuristics.json','utf8')) : {};
            const files = fs.existsSync('files_to_analyze.json') ? JSON.parse(fs.readFileSync('files_to_analyze.json','utf8')) : [];
            let json = { overall: "Unknown", items: [] };
            if (fs.existsSync('ai_summary_structured.json')) {
              try { json = JSON.parse(fs.readFileSync('ai_summary_structured.json','utf8')); } catch(e) { json = { overall:"Unknown", items: [], note:"parse error" }; }
            }

            const overallMap = { "Block":"ì°¨ë‹¨ í•„ìš”", "Manual review":"ìˆ˜ë™ ê²€í†  í•„ìš”", "Low":"ë‚®ìŒ", "None":"ì·¨ì•½ì  ì—†ìŒ" };
            const overallKor = overallMap[json.overall] || json.overall || "ì•Œ ìˆ˜ ì—†ìŒ";

            const md = [];
            md.push("### ğŸ¤– AI Security Review (ìë™ ë³´ê³ )");
            md.push("");
            md.push(`**ì „ì²´ íŒë‹¨:** ${overallKor}`);
            md.push("");

            md.push("#### ë¶„ì„ ëŒ€ìƒ íŒŒì¼ ëª©ë¡ (ìš°ì„ ìˆœìœ„)");
            md.push("");
            md.push("|íŒŒì¼|ìš°ì„ ìˆœìœ„|");
            md.push("|---|---|");
            files.forEach(f=>{
              const pr = /bad/i.test(f) ? "HIGH (filename contains 'bad')" : "normal";
              md.push(`|${f}|${pr}|`);
            });
            md.push("");

            md.push("#### Heuristic ì„ ê²€ì‚¬ ìš”ì•½");
            md.push("");
            md.push("|íŒŒì¼|ê²€ì¶œ íŒ¨í„´(ìƒ˜í”Œ)|");
            md.push("|---|---|");
            Object.keys(heur).forEach(f=>{
              const arr = heur[f] || [];
              const summary = arr.slice(0,6).map(h=>`line ${h.line}:${h.pattern}`).join("<br>") || "-";
              md.push(`|${f}|${summary}|`);
            });
            md.push("");

            md.push("#### ìƒì„¸ ê²°ê³¼");
            md.push("");
            if (!json.items || json.items.length === 0) {
              md.push("_ì·¨ì•½ì  ì—†ìŒ (ìë™ ë¶„ì„)_");
            } else {
              md.push("|íŒŒì¼|ë¼ì¸|ì·¨ì•½ì  ì¡´ì¬|ì‹¬ê°ë„|CWE|OWASP|ìš”ì•½(í•œêµ­ì–´)|ê¶Œê³ (í•œêµ­ì–´)|");
              md.push("|---|---:|---|---|---|---|---|---|");
              json.items.forEach(it=>{
                const file = it.file || '-';
                const line = it.line || '-';
                const present = (it.present===false) ? 'ì•„ë‹˜' : 'ìˆìŒ';
                const sev = it.severity || '-';
                const cwe = it.cwe || '-';
                const owasp = it.owasp || '-';
                const desc = (it.details_ko || '-').replace(/\r?\n/g,' ');
                const rec = (it.recommendation_ko || '-').replace(/\r?\n/g,' ');
                md.push(`|${file}|${line}|${present}|${sev}|${cwe}|${owasp}|${desc}|${rec}|`);
              });
            }
            md.push("");
            md.push("> â€» ìë™ ë„êµ¬ ê²°ê³¼ì…ë‹ˆë‹¤. 'ì°¨ë‹¨ í•„ìš”' ë˜ëŠ” 'ì¹˜ëª…ì ' í•­ëª©ì€ ë‹´ë‹¹ìê°€ ì¦‰ì‹œ ìˆ˜ë™ ê²€í† Â·ì¡°ì¹˜í•˜ì„¸ìš”.");
            md.push("");
            md.push("<details><summary>Raw artifacts (heuristics & structured JSON)</summary>");
            md.push("");
            md.push("```json");
            if (fs.existsSync('heuristics.json')) md.push(fs.readFileSync('heuristics.json','utf8'));
            md.push("");
            md.push(fs.existsSync('ai_summary_structured.json') ? fs.readFileSync('ai_summary_structured.json','utf8') : '{}');
            md.push("```");
            md.push("</details>");
            md.push("");
            md.push("_ìë™ ìƒì„± ë¦¬í¬íŠ¸ â€” ë‹´ë‹¹ì ê²€í†  í•„ìˆ˜_");

            const body = md.join("\n");
            const isPR = !!context.payload.pull_request;
            if (isPR) {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.payload.pull_request.number,
                body
              });
            } else {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `[AI Security Scan] ìë™ ë¦¬í¬íŠ¸ - ${new Date().toISOString().slice(0,10)}`,
                body
              });
            }
